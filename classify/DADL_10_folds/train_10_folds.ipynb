{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'random'\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "metric = {\n",
    "    'name': 'Grand Mean',\n",
    "    'goal': 'maximize'\n",
    "}\n",
    "\n",
    "sweep_config['metric'] = metric"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "parameters_dict = {\n",
    "    'dropout': {\n",
    "          'values': [0.71]\n",
    "        },\n",
    "\n",
    "    'learning_rate': {\n",
    "        'values': [0.0005]\n",
    "        },\n",
    "\n",
    "    'batch_size': {\n",
    "        'values': [4096]\n",
    "        },\n",
    "\n",
    "    'data_augmentation_multiple': {\n",
    "        'values': [5]\n",
    "        }\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "sweep_config['parameters'] = parameters_dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 3fo2ht7f\n",
      "Sweep URL: https://wandb.ai/imucs/sub_loc_train/sweeps/3fo2ht7f\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"sub_loc_train\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'random',\n",
      " 'metric': {'goal': 'maximize', 'name': 'Grand Mean'},\n",
      " 'parameters': {'batch_size': {'values': [4096]},\n",
      "                'data_augmentation_multiple': {'values': [5]},\n",
      "                'dropout': {'values': [0.71]},\n",
      "                'learning_rate': {'values': [0.0005]}}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(sweep_config)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "feature_pd = pd.read_csv('/home/kongge/projects/new_protT5/data/DPC_T5_578_right.csv')\n",
    "labels_pd = pd.read_csv(\"/home/kongge/projects/new_protT5/data/mutil_label_578.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from dataAug.tools import MLDA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "from dataAug.all_tools import dataAugSMOTE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "\n",
    "smote_multiple = {}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "import time\n",
    "from classify.targeTools import testThresholdFive, Accuracy\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "from classify.Classify_adjust import ModelClassify\n",
    "def train_and_val(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "        kf = KFold(n_splits=10, shuffle=True)\n",
    "        model_discord = []\n",
    "\n",
    "        multi_label_samples = labels_pd[(labels_pd.sum(axis=1) >= 2)]\n",
    "        multi_label_indices = multi_label_samples.index\n",
    "        multi_features_samples = feature_pd.loc[multi_label_indices]\n",
    "        ML_G_X, ML_G_y = MLDA(multi_features_samples, multi_label_samples, config.data_augmentation_multiple)\n",
    "\n",
    "        G_feature, G_label = dataAugSMOTE(feature_pd, labels_pd, config.data_augmentation_multiple, 1424)\n",
    "        G_feature = pd.concat([G_feature, ML_G_X], axis=0)\n",
    "        G_label = pd.concat([G_label, ML_G_y], axis=0)\n",
    "        feature_all = pd.concat([feature_pd, G_feature], axis=0)\n",
    "        label_all = pd.concat([labels_pd, G_label], axis=0)\n",
    "        print(feature_all.shape)\n",
    "        print(label_all.shape)\n",
    "        for train_index, test_index in kf.split(feature_all):\n",
    "            train_data = feature_all.iloc[train_index]\n",
    "            train_label = label_all.iloc[train_index]\n",
    "\n",
    "            test_data = feature_all.iloc[test_index]\n",
    "            test_label = label_all.iloc[test_index]\n",
    "\n",
    "            datasetTrain = TensorDataset(torch.tensor(train_data.values), torch.tensor(train_label.values))\n",
    "            batch_size = config.batch_size\n",
    "            dataloaderTrain = DataLoader(datasetTrain, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "            datasetTest = TensorDataset(torch.tensor(test_data.values), torch.tensor(test_label.values))\n",
    "\n",
    "            batch_size = len(datasetTest)\n",
    "            dataloaderTest = DataLoader(datasetTest, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "            model = ModelClassify(drop_rate=config.dropout, num_class=5, feature_num=1424)\n",
    "            criterion = torch.nn.BCELoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "            import warnings\n",
    "            warnings.filterwarnings(\"ignore\")\n",
    "            GMList = {}\n",
    "            epochs = 100\n",
    "            for epoch in range(epochs):\n",
    "                model.train()\n",
    "                total_loss = 0.0\n",
    "                for idx, data in enumerate(dataloaderTrain, 0):\n",
    "                    inputs, labels = data\n",
    "                    labels = labels.float()\n",
    "                    inputs = inputs.float()\n",
    "                    out = model(inputs)\n",
    "                    loss = criterion(out, labels)\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    total_loss += loss.item()\n",
    "                avg_loss = total_loss / len(dataloaderTrain)\n",
    "                threshold = 0.5\n",
    "                labels_cov = torch.where(out > threshold, torch.tensor(1), torch.tensor(0))\n",
    "                print(f\"Epoch [{epoch+1}/{epochs}], Average Loss: {avg_loss:.4f}, ACC: {Accuracy(labels.int(), labels_cov)}\")\n",
    "            GMScore1 = testThresholdFive(epoch, model, dataloaderTest, class_num=5)\n",
    "            GMList[epoch] = GMScore1\n",
    "            t = time.time()\n",
    "            best_key = max(GMList, key=GMList.get)\n",
    "            best_value = GMList[best_key]\n",
    "\n",
    "            best_value = [x.item() if isinstance(x, torch.Tensor) else x for x in best_value]\n",
    "            model_discord.append(best_value)\n",
    "        model_discord_column_means = [sum(col) / len(col) for col in zip(*model_discord)]\n",
    "        smote_multiple[int(t)] = model_discord_column_means\n",
    "        wandb.log({\"Grand Mean\": model_discord_column_means[0]})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[33mWARNING\u001B[0m Calling wandb.login() after wandb.init() has no effect.\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, train_and_val, count=30)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "{}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_multiple"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import json\n",
    "file = open(\"/home/kongge/projects/new_protT5/data/dictionary_data_DADL.json\", \"w\")\n",
    "json.dump(smote_multiple, file)\n",
    "file.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
